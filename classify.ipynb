{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets,transforms,models\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "BATCH_SIZE=64\n",
    "NUM_CLASSES = 39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_split_train_test(datadir,valid_size=.2):\n",
    "    train_transforms = transforms.Compose([transforms.Resize(256),\n",
    "                                           transforms.RandomCrop(256),\n",
    "                                           transforms.RandomHorizontalFlip(),\n",
    "                                           transforms.ToTensor(),\n",
    "                                          transforms.Normalize(\n",
    "                                          mean=[0.485,0.456,0.406],\n",
    "                                          std=[0.229,0.224,0.225])])\n",
    "                                        \n",
    "    test_transforms = transforms.Compose([transforms.Resize(256),\n",
    "                                           transforms.RandomCrop(256),\n",
    "                                           transforms.RandomHorizontalFlip(),\n",
    "                                           transforms.ToTensor(),\n",
    "                                          transforms.Normalize(\n",
    "                                          mean=[0.485,0.456,0.406],\n",
    "                                          std=[0.229,0.224,0.225])])\n",
    "                                          \n",
    "    \n",
    "    train_data = datasets.ImageFolder(datadir,transform=train_transforms)\n",
    "    test_data = datasets.ImageFolder(datadir,transform=test_transforms)\n",
    "    \n",
    "    num_train = len(train_data)\n",
    "    print('train images size is:{}'.format(num_train))\n",
    "    \n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size*num_train))\n",
    "    \n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    train_idx,test_idx = indices[split:],indices[split:]\n",
    "    \n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(test_idx)\n",
    "    \n",
    "    trainloader = torch.utils.data.DataLoader(train_data,\n",
    "                                             sampler=train_sampler,batch_size=BATCH_SIZE)\n",
    "    testloader = torch.utils.data.DataLoader(test_data,\n",
    "                                            sampler=test_sampler,batch_size=BATCH_SIZE)\n",
    "    \n",
    "    return trainloader,testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train images size is:194899\n",
      "['amanita+muscaria', 'amanita+pantherina', 'amanita+phalloides', 'amanita+verna', 'armillaria+gallica', 'armillaria+mellea', 'boletus+betulicola', 'boletus+edulis', 'boletus+pinicola', 'boletus+pinophilus', 'boletus+satanas', 'cantharellus+cibarius', 'coprinellus+micaceus', 'fomes+fomentarius', 'fomitopsis+pinicola', 'galerina+marginata', 'ganoderma+pfeifferi', 'hypholoma+fasciculare', 'lactarius+delicious', 'lactarius+deterrimus', 'leccinum+melaneum', 'leccinum+scabrum', 'leccinum+variicolor', 'leccinum+versipelle', 'leccinum+vulpinum', 'mycena+galericulata', 'pluteus+cervinus', 'psathyrella+candolleana', 'russula+aeruginea', 'russula+claroflava', 'russula+vesca', 'russula+xerampelina', 'suillus+flavidus', 'suillus+granulatus', 'suillus+grevillei', 'suillus+luteus', 'trametes+versicolor', 'tricholoma+scalpturatum', 'xerocomellus+chrysenteron']\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "trainloader,testloader = load_split_train_test(data_dir,.2)\n",
    "print(trainloader.dataset.classes)\n",
    "print(len(trainloader.dataset.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outputSize(in_size,kernel_size,stride,padding):\n",
    "    output = int((in_size-kernel+2*(padding))/stride)+1\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 61*61, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, NUM_CLASSES)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if(DEBUG):\n",
    "            print('first_shape {}'.format(x.shape))\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        if(DEBUG):\n",
    "            print('second_shape {}'.format(x.shape))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        if(DEBUG):\n",
    "            print('third_shape before view{}'.format(x.shape))\n",
    "        x = x.view(-1, 16 * 61*61)\n",
    "        if(DEBUG):\n",
    "            print('4nd_shape after view{}'.format(x.shape))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        if(DEBUG):\n",
    "            print('5nd_shape {}'.format(x.shape))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        if(DEBUG):\n",
    "            print('6nd_shape {}'.format(x.shape))\n",
    "        x = self.fc3(x)\n",
    "        if(DEBUG):\n",
    "            print('7nd_shape {}'.format(x.shape))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = SimpleCNN()\n",
    "cnn = cnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    }
   ],
   "source": [
    "print(len(trainloader.dataset.classes)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createLossAndOptimizer(net,learning_rate=0.001):\n",
    "    \n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    optimizer = optim.Adam(net.parameters(),lr=learning_rate)\n",
    "    \n",
    "    return(loss,optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imgshow(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg,(1,2,0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(tr_loader,criterion,optim,\n",
    "                  device='cuda',net=SimpleCNN(),n_epoch=5):\n",
    "    net = net.to(device)\n",
    "    for epoch in range(n_epoch):\n",
    "        running_loss = 0.0\n",
    "        for i,data in enumerate(tr_loader,0):\n",
    "            #getting inputs and labels for batch\n",
    "            inputs,labels = data[0].to(device),data[1].to(device)\n",
    "            optim.zero_grad()\n",
    "            #forward pass\n",
    "            outputs = net.forward(inputs)\n",
    "            _,out = torch.max(outputs.data,1)\n",
    "            if(DEBUG):\n",
    "                print('outputs shape {}'.format(outputs.shape))\n",
    "                print('labels shape {}'.format(labels.shape))\n",
    "                print(outputs[0])\n",
    "            loss = criterion(outputs,labels)\n",
    "            #backward pass\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            #print what we've got\n",
    "            running_loss+=loss.item()\n",
    "            if i%30==29:\n",
    "                print('[%d,%5d] loss: %.3f' % (epoch+1,i+1,running_loss/30))\n",
    "                running_loss = 0.0\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   30] loss: 3.685\n",
      "[1,   60] loss: 3.661\n",
      "[1,   90] loss: 3.642\n",
      "[1,  120] loss: 3.567\n",
      "[1,  150] loss: 3.505\n",
      "[1,  180] loss: 3.487\n",
      "[1,  210] loss: 3.449\n",
      "[1,  240] loss: 3.391\n",
      "[1,  270] loss: 3.349\n"
     ]
    }
   ],
   "source": [
    "loss,optimizer = createLossAndOptimizer(cnn)\n",
    "train_network(trainloader,loss,optimizer,device,cnn,25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on validation part of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images,labels = data[0].to(device),data[1].to(device)\n",
    "        output = cnn(images)\n",
    "        _,predicted = torch.max(output.data,1)\n",
    "        total+=labels.size(0)\n",
    "        correct+=(predicted == labels).sum().item()\n",
    "        \n",
    "print('Accuracy of the network is %d %%'%(100*correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(NUM_CLASSES))\n",
    "class_total = list(0. for i in range(NUM_CLASSES))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images,labels = data[0].to(device),data[1].to(device)\n",
    "        outputs = cnn(images)\n",
    "        _,predicted = torch.max(outputs,1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(BATCH_SIZE):\n",
    "            label = labels[i]\n",
    "            class_correct[label]+=c[i].item()\n",
    "            class_total[label] += 1\n",
    "            \n",
    "for i in range(NUM_CLASSES):\n",
    "    print('Accuracy of %10s : %2d %%' % (\n",
    "    trainloader.dataset.classes[i], 100*class_correct[i]/class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
